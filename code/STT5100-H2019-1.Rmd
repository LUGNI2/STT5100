---
title: "STT5100 #1 - Modèle Linéaire Simple"
author: "Arthur Charpentier"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Explaining the Weight of Students

```{r}
Davis=read.table(
"http://socserv.socsci.mcmaster.ca/jfox/Books/Applied-Regression-2E/datasets/Davis.txt")
Davis[12,c(2,3)]=Davis[12,c(3,2)]
Davis=data.frame(X1=Davis$height / 30.48,
                 X2=Davis$sex,
                 Y=Davis$weight * 2.204622)
str(Davis)
Y = Davis$Y
library(MASS)
fitdistr(Y,"normal")
```


```{r}
hist(Y,probability = TRUE, col=rgb(0,0,1,.4))
x=seq(min(Y),max(Y),length=251)
y=dnorm(x,fitdistr(Y,"normal")$estimate[1],fitdistr(Y,"normal")$estimate[2])
lines(x,y,col="red")
```

## Regression - on a continous variable

$${ y_{i}=\alpha +\beta x_{i}+\varepsilon _{i}}$$

```{r}
X1 = Davis$X1
plot(X1,Y)
mean(Y)
mean(X1)
abline(v=mean(X1),col="red",lty=2)
abline(h=mean(Y),col="red",lty=2)
```

 $${\displaystyle {\begin{aligned}{\hat {\alpha }}&={\bar {y}}-{\hat {\beta }}\,{\bar {x}},\\{\hat {\beta }}&={\frac {\sum _{i=1}^{n}(x_{i}-{\bar {x}})(y_{i}-{\bar {y}})}{\sum _{i=1}^{n}(x_{i}-{\bar {x}})^{2}}}=\text{corr}(x,y)\cdot{\frac {s_{y}}{s_{x}}}.\\[6pt]\end{aligned}}} $$

```{r}
cor(X1,Y)
(Bhat = cor(X1,Y) * sd(Y)/sd(X1))
(Ahat = mean(Y) - Bhat*mean(X1))
plot(X1,Y)
abline(v=mean(X1),col="red",lty=2)
abline(h=mean(Y),col="red",lty=2)
abline(a = Ahat, b=Bhat, lwd=3, col="red")
```

```{r}
Y_hat = Ahat + Bhat*X1
E_hat = Y-Y_hat
plot(X1,Y)
abline(a = Ahat, b=Bhat, lwd=3, col="red")
segments(X1,Y,X1,Y_hat,col="light blue")
```

```{r}
SCR = function(B){sum((Y - (Ahat + B*X1))^2)}
x=seq(50,100)
y=Vectorize(SCR)(x)
plot(x,y,type="l",ylab="Somme des carres des erreurs")
abline(v=Bhat,col="red",lty=2)
```

```{r}
reg = lm(Y~X1, data=Davis)
summary(reg)
```

$${\displaystyle s_{\hat {\beta }}={\sqrt {\frac {{\frac {1}{n-2}}\sum _{i=1}^{n}{\hat {\varepsilon }}_{i}^{\,2}}{\sum _{i=1}^{n}(x_{i}-{\bar {x}})^{2}}}}}$$

```{r}
n=nrow(Davis)
(sigma2 = 1/(n-2)*sum(E_hat^2))
sqrt(sigma2)
sqrt( sigma2 / sum( (X1-mean(X1))^2 ) )
```

$$
{\displaystyle s_{\hat {\alpha }}=s_{\hat {\beta }}{\sqrt {{\frac {1}{n}}\sum _{i=1}^{n}x_{i}^{2}}}={\sqrt {{\frac {1}{n(n-2)}}\left(\sum _{i=1}^{n}{\hat {\varepsilon }}_{j}^{\,2}\right){\frac {\sum _{i=1}^{n}x_{i}^{2}}{\sum _{i=1}^{n}(x_{i}-{\bar {x}})^{2}}}}}} 
$$

```{r}
sqrt( sigma2 / sum( (X1-mean(X1))^2 ) )*sqrt(mean(X1^2))
```

$${\displaystyle y=(\alpha +\beta x )\in \left[{\hat {\alpha }}+{\hat {\beta }}x \pm t_{n-2}^{*}{\sqrt {\left({\frac {1}{n-2}}\sum {\hat {\varepsilon }}_{i}^{\,2}\right)\cdot \left({\frac {1}{n}}+{\frac {(x -{\bar {x}})^{2}}{\sum (x_{i}-{\bar {x}})^{2}}}\right)}}\right]}$$
```{r}
(t_star = qt(1-.05/2,n-2))
qnorm(1-.05/2)
```

## Regression - on a categorical variable

```{r}
boxplot(Y~X2,data=Davis)
mean(Davis$Y[Davis$X2=="M"])
t.test(x = Davis$Y[Davis$X2=="M"],
       y = Davis$Y[Davis$X2=="F"])
```

```{r}
reg = lm(Y ~ 0+X2, data=Davis)
summary(reg)
reg = lm(Y ~ X2, data=Davis)
summary(reg)
```

# Visualization

```{r}
data(anscombe)
plot(anscombe$x1,anscombe$y1)
abline(lm(y1~x1,data=anscombe),col="red",lwd=3)
summary(lm(y1~x1,data=anscombe))
plot(anscombe$x2,anscombe$y2)
abline(lm(y2~x2,data=anscombe),col="red",lwd=3)
summary(lm(y2~x2,data=anscombe))
plot(anscombe$x3,anscombe$y3)
abline(lm(y3~x3,data=anscombe),col="red",lwd=3)
summary(lm(y3~x3,data=anscombe))
plot(anscombe$x4,anscombe$y4)
abline(lm(y4~x4,data=anscombe),col="red",lwd=3)
summary(lm(y4~x4,data=anscombe))
```